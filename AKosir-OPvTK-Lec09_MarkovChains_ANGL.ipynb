{
  "cells": [
    {
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "<img style=\"float: center; width: 100%\" src=\"https://raw.githubusercontent.com/andrejkk/TalksImgs/master/FrontSlideUpperBan.png\">\n<p style=\"margin-bottom:2cm;\"></p>\n\n<center>\n    <H1> 9. Markov chains </H1>\n   \n\n\n<br><br>\n    <H3> Andrej Košir, Lucami, FE </H4>\n    \n    <H4> Kontakt: prof. dr. Andrej Košir, andrej.kosir@lucami.fe.uni-lj.si, skype=akosir_sid </H4>\n</center>\n\n\n<p style=\"margin-bottom:2cm;\"></p>\n<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 1 </div>\n<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
    },
    {
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## ■ Intro\n\n- Goals: \n    - Markov chain modeling\n    - Markov chain state analysis \n- Stochastic process on finite states, most useful and used. We limit to:\n    - Discrete times\n    - Discrete state space (finite or countably many states)\n- Case: user behavior\n- Usage\n    - Finite state machine analysis: software, TC \u000bsystem, ...\n    - Models in economy\n- What are questions:\n    - Distributions of visits\n    - Long term behavior\n    - Absorption of states\n\n\n\n<figure>\n<img style=\"float: center; width: 300px; margin: 0px 20px 20px 0px;\" src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/MarkovChain_Emotions.png\">\n  <figcaption></figcaption>\n</figure>\n\n<figure>\n<img style=\"float: right; width: 200px; margin: -320px 20px 20px 0px;\" src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/MarkovChain_Marker.png\">\n  <figcaption></figcaption>\n</figure>\n\n\n<p style=\"margin-bottom:2cm;\"></p>\n<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 2 </div>\n<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
    },
    {
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## ■ Sections \n\n\n9.1. Definition, basic characteristics\n\n■ Markov chain definition $\\large{*}$\n\n■ Transition matrix, distribution of states $\\large{*}$\n\n\n9.2. Classification of states\n\n■ Communication of states and period $\\large{*}$\n\n■ Recurrent and transient state $\\large{*}$\n\n■ Ergodic Markov chain and return times\n\n■ Stationary (limit) distribution $\\large{*}$\n \n■ Finite Markov chain $\\large{*}$\n\n\n9.3. Transition matrix estimation\n\n■ Transition probability estimation\n\n■ Confidence intervals and quantiles\n\n■ Sample size determination\n\n■ Numerical aspect\n\n■ Case: telecommunication service user modeling\n\n\n\n<p style=\"margin-bottom:2cm;\"></p>\n<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 3 </div>\n<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
    },
    {
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## 9.1. Definition, basic characteristics\n\n■ Markov chain definition\n\n■ Transition matrix, distribution of states\n\n\n\n<p style=\"margin-bottom:2cm;\"></p>\n<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 4 </div>\n<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
    },
    {
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## ■ Markov chain definition\n\n\n- State space $S$, $m=|S|$\n    - Finite, countable, continuous\n\n\n- Time $T$\n    - Discrete, continuous\n\n\n- Stochastic process: \n$$ X_n : T \\to S $$\n\n\n- Discrete Markov chain is a discrete time discrete space Markov chain having Markov property\n$$ P[X_{n+1}|_{X_n, X_{n-1}, \\ldots, X_0}] = P[X_{n+1}|_{X_n}] = P[X_1|_{X_0}] $$\n\n\n- Transition probability of one step\n$$ p_{ij} = P[X_{n+1}=j|_{X_n=i}] $$\n\n\n- Finite state space means there is a matrix  of transition probabilities\n$$ P = [p_{ij}], \\; i,j\\in S. $$\n    - Row sums are equal to 1. \n\n\n\n<p style=\"margin-bottom:2cm;\"></p>\n<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 5 </div>\n<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nfrom sympy import Matrix\nfrom sympy.functions import re\n\n# Case 1 \n# Transition matrix\nP = np.array([[0.7, 0.2, 0.1, 0.0], \n              [0.2, 0.5, 0.2, 0.1], \n              [0.05, 0.15, 0.6, 0.2], \n              [0.0, 0.2, 0.0, 0.8]])",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## ■ Transition matrix, distribution of states\n\n\n\n- Transition matrix for $n$ steps\n    - $p_{ij}^{(n)} = P[X_{k+n}|_{X_k=i}]$, $P^{(n)}=[p_{ij}^{(n)}]$\n    - From total probability formula\n    $$ P^{(n)} = P^n $$\n    \n\n- Distribution of states: \n$$ \\pi_i^n = P[X_n=i], \\pi^n = [\\pi_1^n, \\ldots, \\pi_i^n] $$\n    - Initial distribution: $\\pi^0$. If initial state $X_0=i_0$ is known\n    $$ \\pi^0=\\delta_{i_0 i} $$\n    - From total probability formula:\n    $$ \\pi^n = P^{(n)} \\pi^0 $$\n    - More on limit distribution later\n\n\n\n<p style=\"margin-bottom:2cm;\"></p>\n<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 6 </div>\n<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
    },
    {
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## 9.2. Classification of states\n\n\n■ Communication of states and period\n\n■ Recurrent and transient state\n\n■ Ergodic Markov chain and return times\n\n■ Stationary (limit) distribution\n\n■ Finite Markov chain\n\n\n\n<p style=\"margin-bottom:2cm;\"></p>\n<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 7 </div>\n<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
    },
    {
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## ■ Communication of states and period\n\n\n- Accessible state\n    - State $j$ is accessible from state $i$ if $\\exists n: p_{ij}^{(n)}>0$. Notation $i\\leftrightarrow j$\n    - Two states communicate if $i\\rightarrow$ and $i \\leftarrow j$, denoted by $i\\leftrightarrow j$\n    - „Communicate“ is equivalent relation\n\n\n- Markov chain is irreducible if there are only one single communicating class\n\n\n- Period of state $i$ ia denoted by $d(i)$ is greatest common divisor of all $n$ such that $P_{ii}^{(n)} > 0$:  \n    - If $i\\leftrightarrow j$ then $d(i) = d(j)$;\n    - State is aperiodic if $d(i)=1$;\n\n\n\n- State $i$ is zero state if \n$$ \\lim_{n\\to\\infty} P_{ii}^{(n)} = 0. $$\n\n\n<p style=\"margin-bottom:2cm;\"></p>\n<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 8 </div>\n<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ---------------------------------------------------------------------------------------------------\n# Classification of states\nprint ('Transition matrix P=\\n', P)\nprint ('\\nTransition matrix P^2=\\n', np.linalg.matrix_power(P, 2))\n\n# All entries of P^2 are non-zero\n# => All atates are connected",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Transition matrix P=\n [[0.7  0.2  0.1  0.  ]\n [0.2  0.5  0.2  0.1 ]\n [0.05 0.15 0.6  0.2 ]\n [0.   0.2  0.   0.8 ]]\n\nTransition matrix P^2=\n [[0.535 0.255 0.17  0.04 ]\n [0.25  0.34  0.24  0.17 ]\n [0.095 0.215 0.395 0.295]\n [0.04  0.26  0.04  0.66 ]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# ---------------------------------------------------------------------------------------------------\n# Decompose transition matrix\n# Use Jordan decomposition\n#mP = Matrix(P)\n#mB, mJ = mP.jordan_form()\n#B, J = np.array(mB), np.array(mJ)\nB = np.array([[-0.5,-0.776313,0.659526,-0.413722],\n              [-0.5,-0.212847,-0.11514,0.830469],\n              [-0.5,0.283275,-0.73692,-0.123153],\n              [-0.5,0.521335,0.0933625,-0.352121]])\nJ = np.array([[1.,0,0,0],\n              [0,0.718345,0,0],\n              [0,0,0.553349,0],\n              [0,0,0,0.328305]])\n\n# Test decomposition\nerr_mat = P - np.dot(B, np.dot(J, np.linalg.inv(B)))\nprint ('\\nDecomposition error norm = ', np.linalg.norm(err_mat))",
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\nDecomposition error norm =  7.249920892047682e-07\n"
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## ■ Recurrent and transient state\n\n\n- Probability of return after exactly $n$ steps\n$$ f_{ij}^n = P[X_n=j|_{X_{n-1}\\ne j, \\ldots, X_1\\ne j, X_0=i}] $$\n\n\n- Random variable of transitions from $i$ to $j$ is denoted by $T_{i}$ and its distribtion is \n$$ T_{ij} \\sim \\left(\\matrix{0 & 1 & 2 & \\ldots \\cr f_{ij}^0 & f_{ij}^1 & f_{ij}^2 & \\ldots}\\right) $$\n    - Denote $T_i = T_{ii}$\n    - Denote $\\sum_{n=0}^\\infty f_{ii}^n = f_{ii}^*$. Value \n    $$ 1 - f_{ii}^* $$\n    is a probability that Markov Chain newer returns to state 𝑖 after leaving it. \n\n\n- State $i$ is **recurrent** if $f_{ii}^* = 1$. State is **transient** if it is not recurrent.\n    - Recurrence and transience are communicating class properties\n\n\n- We have: state $i$ is recurrent if and only if\n$$ \\sum_{n=1}^\\infty P_{ii}^{(n)} = \\infty $$\n\n- Also: if $i\\leftrightarrow j$ then both states are either transient or recurrent  \n\n\n\n<p style=\"margin-bottom:2cm;\"></p>\n<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 9 </div>\n<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Recurent, transient? \n\n# Eigenvalues\neigVals, eigVecs = np.linalg.eig(P.T)\n\n# Get it sorted\nidx = eigVals.argsort()[::-1]   \neigVa = eigVals[idx]\neigVc = eigVecs[:,idx]\n\nlas_bf =  (1./(1-eigVa[1:4]))-1\nprint ('las_bf', las_bf)\n           \nsumJn = np.diag(np.insert(las_bf, 0, np.inf))\nprint ('\\nSum J^n\\n', sumJn)\n\nsumPn = np.dot(B, np.dot(sumJn, np.linalg.inv(B)))\nprint ('\\nSum P^n\\n', sumPn)\n\n# Since all diagonal elements of sum P^n are infinity\n#  => all states are recurrent",
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "las_bf [2.55044912 1.23888596 0.48877142]\n\nSum J^n\n[[       inf 0.         0.         0.        ]\n [0.         2.55044912 0.         0.        ]\n [0.         0.         1.23888596 0.        ]\n [0.         0.         0.         0.48877142]]\n\nSum P^n\n[[inf inf inf inf]\n [inf inf inf inf]\n [inf inf inf inf]\n [inf inf inf inf]]\n"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "def inf_sum(a_lst):\n    return [(la/(1.0-la) if la < 1 else np.infty) for la in a_lst]\n\n# ---------------------------------------------------------------------------------------------------\n# Are states recurrent?\n# Compute sum of P^n\nsumJ = np.diag(inf_sum(np.diag(J)))\nsumP = np.dot(B, np.dot(sumJ, np.linalg.inv(B)))\n\nprint ('\\nSum of P^n = \\n', sumP)\n# => All states are reccurent ",
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\nSum of P^n = \n[[inf inf inf inf]\n [inf inf inf inf]\n [inf inf inf inf]\n [inf inf inf inf]]\n"
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## ■ Ergodic Markov chain and return times\n\n\n- Markov chain is **Ergodic** if it is \n    - Irreducible\n    - Recurrent (all states are recurrent)\n    - Aperiodic (all states are aperiodic)\n    - Nonzero (all states are positive)\n    \n    \n- Expected return time: \n$$ E(T_i) = \\sum_{n=0}^\\infty n f_{ii}^{(n)} $$\n\n\n- In ergodic Markov chain\n$$ \\lim_{n\\to\\infty} P_{ii}^{(n)} = \\frac{1}{E(T_i)} $$\n$$ \\lim_{n\\to\\infty} P_{ij}^{(n)} = \\lim_{n\\to\\infty} P_{ii}^{(n)} $$ \n\n\n- Recurrent **zero** state $i$:\n$$ \\lim_{n\\to\\infty} P_{ii}^{(n)} = 0 \\; \\Leftrightarrow \\;  E(T_i) = \\infty  $$\n\n\n- Recurrent **positive** = **ergodic** state $i$: \n$$ \\lim_{n\\to\\infty} P_{ii}^{(n)} > 0 \\; \\Leftrightarrow \\; E(T_i) < \\infty  $$\n\n\n\n<p style=\"margin-bottom:2cm;\"></p>\n<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 10 </div>\n<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def inf_lim(a_lst):\n    return [(0 if la < 1 else 1) for la in a_lst]\n\n# ---------------------------------------------------------------------------------------------------\n# Zero or positive states?\n# Compute lim of P^n\nlimJ = np.diag(inf_lim(np.diag(J)))\nlimP = np.dot(B, np.dot(limJ, np.linalg.inv(B)))\n\nprint ('\\nlim of P^n = \\n', limP)\n\n# Since all lim P^n are positive\n# => all states are positive\n\n# Expected times of visits\nETi = 1.0/np.diag(limP)\n\nprint ('\\nExpected number of visits py states:\\n', ETi)",
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\nlim of P^n = \n[[0.21301781 0.27218919 0.18934915 0.32544385]\n [0.21301781 0.27218919 0.18934915 0.32544385]\n [0.21301781 0.27218919 0.18934915 0.32544385]\n [0.21301781 0.27218919 0.18934915 0.32544385]]\n\nExpected number of visits py states:\n[4.69444311 3.67391519 5.28124903 3.07272668]\n"
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## ■ Stationary (limit) distribution\n\n\n- State distribution after $n$ steps \n$$ \\pi_i^n = P[X_n=i], \\qquad \\pi^n = [\\pi_1^n, \\ldots, \\pi_i^n] $$\n\n\n- Stationary (limit) distribution: \n  $$ \\pi = \\lim_{n\\to\\infty} \\pi^n $$\n    - When uniquely defined: when all states are recurrent positive\n\n\n- Ergodic MC: stationary distribution exists\n- Stationary distribution of ergodic MC chain is left eigenvector of transition matrix: \n  $$ \\pi^\\top = \\pi^\\top P. $$\n\n\n- Note: in an ergodic MC a stationary distribution independent of initial distribution $\\pi^0$.\n\n\n\n<p style=\"margin-bottom:2cm;\"></p>\n<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 11 </div>\n<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# ---------------------------------------------------------------------------------------------------\n# Limit distribuion\neigVals, eigVecs = np.linalg.eig(P.T)\npi = eigVecs[:, 0]/sum(eigVecs[:, 0])\n\nprint ('\\neigVals=\\n', eigVals)\n#print '\\neigVecs=\\n', eigVecs\nprint ('\\nLimit distribution =', pi)",
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\neigVals=\n[1.         0.32830522 0.71834549 0.55334929]\n\nLimit distribution = [0.21301775 0.27218935 0.18934911 0.32544379]\n"
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## ■ Probability of absorption\n\n\n- Absorption: chain never leave a subset of states $S_0 \\subset S$\n\n\n- What is the probability of absorption?\n\n\n- If a chain starts in transient state, then either:\n    1. It leaves a set of transient states with probability of 1\n    2. It enters a set of recurrent states with probability of 1\n\n\n- Absorbing states $i$: the only state of an absorbing state\nWe have: $i$ absorbing if and only if \n$P_{ii}=1$\n\n\n- Let $i\\in S$ be a transient state, $S_e$ a set of recurrent states:<br>\nProbability of absorption: $\\pi_i(S_e)$ is the probability MC with $X_0=i$ gets absorbed into the set of states $S_e$\n\n\n- We have\n$$ \\lim_{n\\to\\infty} P_{ij}^{(n)} = \\pi_i(S_e)\\pi_j. $$\n\n\n\n<p style=\"margin-bottom:2cm;\"></p>\n<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 12 </div>\n<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
    },
    {
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## ■ Finite Markov chain\n\n\n- Finite number of states $|S|=m < \\infty$.\n\n\n- Each finite MC has recurrent states!\n\n\n- All recurrent states are positive, that is ergodic and has finite expected return time\n$$ \\lim_{n\\to\\infty} P_{ii}^{(n)} > 0. $$\n\n\n- Classification of states: all states are $S=S_m\\cup S_e$, where\n    - Transient states: $S_m$\n    - Ergodic states: $S_e$\n    \n    \n- Transient matrix is of a block form:\n    - Ergodic states: $1, \\ldots, m-K$\n    - Transient state: $m-K+1, \\ldots, m$\n    $$ P = \\left[\\matrix{S & 0 \\cr R & Q}\\right] $$\n\n- Fundamental matrix:\n$$ N = (I - Q)^{-1}.  $$\n\n\n\n   \n<p style=\"margin-bottom:2cm;\"></p>\n<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 13 </div>\n<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Case 2\nc2P = np.array(\n    [[0.7, 0.3, 0.0, 0.0], \n     [0.2, 0.8, 0.0, 0.0], \n     [0.05, 0.15, 0.6, 0.2], \n     [0.0, 0.2, 0.0, 0.8]])\n\nprint ('Transition matrix P=\\n', c2P)\n",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Transition matrix P=\n [[0.7  0.3  0.   0.  ]\n [0.2  0.8  0.   0.  ]\n [0.05 0.15 0.6  0.2 ]\n [0.   0.2  0.   0.8 ]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ---------------------------------------------------------------------------------------------------\n# Classification of states\nprint ('Transition matrix P=\\n', c2P)\nprint ('\\nTransition matrix P^2=\\n', np.linalg.matrix_power(c2P, 2))\nprint ('\\nTransition matrix P^3=\\n', np.linalg.matrix_power(c2P, 3))\n\n# Matrix multiplications by blocks\n# => 2 x 2 block of zeros stayes the same\n# => There are two connected classes of states",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Transition matrix P=\n [[0.7  0.3  0.   0.  ]\n [0.2  0.8  0.   0.  ]\n [0.05 0.15 0.6  0.2 ]\n [0.   0.2  0.   0.8 ]]\n\nTransition matrix P^2=\n [[0.55  0.45  0.    0.   ]\n [0.3   0.7   0.    0.   ]\n [0.095 0.265 0.36  0.28 ]\n [0.04  0.32  0.    0.64 ]]\n\nTransition matrix P^3=\n [[0.475  0.525  0.     0.    ]\n [0.35   0.65   0.     0.    ]\n [0.1375 0.3505 0.216  0.296 ]\n [0.092  0.396  0.     0.512 ]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ---------------------------------------------------------------------------------------------------\n# Limit distribuion\neigVals, eigVecs = np.linalg.eig(c2P.T)\n\n\n# Get it sorted\nidx = eigVals.argsort()[::-1]   \neigenValues = eigVals[idx]\neigenVectors = eigVecs[:,idx]\n\n# Normalize eigenvector\npi = eigenVectors[:, 0]/sum(eigenVectors[:, 0])\n\nprint ('\\neigVals=\\n', eigenValues)\n#print '\\neigVecs=\\n', eigenVectors\nprint ('\\nLimit distribution =', pi)",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\neigVals=\n [1.  0.8 0.6 0.5]\n\nLimit distribution = [ 0.4  0.6 -0.  -0. ]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ---------------------------------------------------------------------------------------------------\n# Decompose transition matrix\n# Use Jordan decomposition\n#mP = Matrix(c2P)\n#mB, mJ = mP.jordan_form()\n#B, J = np.array(mB), np.array(mJ)\nc2B = np.array([[1.0, 0, 0, 9.0/4],\n              [1.0, 0, 0, -3.0/2],\n              [1.0, 1.0, 1.0, -7.0/8],\n              [1.0, 1.0, 0, 1.0]])\nc2J = np.array([[1.0,0,0,0],\n              [0,4.0/5,0,0],\n              [0,0,3.0/5,0],\n              [0,0,0,1.0/2]])\n\n# Test decomposition\nerr_mat = c2P - np.dot(c2B, np.dot(c2J, np.linalg.inv(c2B)))\nprint ('\\nDecomposition error norm = ', np.linalg.norm(err_mat))",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\nDecomposition error norm =  1.9675159943996247e-16\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def prd(a,b):\n    if np.isinf(a) and b == 0:\n        return 0\n    if np.isinf(b) and a == 0:\n        return 0\n    return a*b\n\ndef myDot(A,B):\n    nA1, nA2, nB2 = A.shape[0], A.shape[1], B.shape[1]\n    AB = np.zeros((nA1,nB2))\n    for i in range(nA1):\n        for j in range(nB2):\n            curr = 0\n            for k in range(nA2):\n                curr += prd(A[i,k], B[k,j])\n            AB[i, j] = curr\n    return AB\n\n# Classification of states\n# Recurent, transient? \n\n# Eigenvalues\neigVals, eigVecs = np.linalg.eig(c2P.T)\n\n# Get it sorted\nidx = eigVals.argsort()[::-1]   \neigVa = eigVals[idx]\neigVc = eigVecs[:,idx]\n\nlas_bf =  (1./(1-eigVa[1:4]))-1\nsumJn = np.diag(np.insert(las_bf, 0, np.inf))\n\nsumPn = myDot(c2B, myDot(sumJn, np.linalg.inv(c2B)))\nprint ('\\nSum P^n\\n', sumPn)\n\n# Since diagonal elements of sum P^n i=1 and i=2 are infinity\n#  => states i=1 and i=2 are recurrent\n# Since diagonal elements of sum P^n i=3 and i=4 are finite\n#  => states i=3 and i=4 are transient\n",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\nSum P^n\n [[inf inf 0.  0. ]\n [inf inf 0.  0. ]\n [inf inf 1.5 2.5]\n [inf inf 0.  4. ]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def inf_lim(a_lst):\n    return [(0 if la < 1 else 1) for la in a_lst]\n\n# ---------------------------------------------------------------------------------------------------\n# Zero or positive states?\n# Compute lim of P^n\nlimJ = np.diag(inf_lim(np.diag(c2J)))\nlimP = np.dot(c2B, np.dot(limJ, np.linalg.inv(c2B)))\n\nprint ('\\nlim of P^n = \\n', limP)\n\n# Since all lim P^n are positive\n# => all states are positive\n\n# Expected times of visits\nETi = 1.0/np.diag(limP)\n\nprint ('\\nExpected number of visits py states:\\n', ETi)\n",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\nlim of P^n = \n [[0.4 0.6 0.  0. ]\n [0.4 0.6 0.  0. ]\n [0.4 0.6 0.  0. ]\n [0.4 0.6 0.  0. ]]\n\nExpected number of visits py states:\n [2.5        1.66666667        inf        inf]\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py:16: RuntimeWarning: divide by zero encountered in true_divide\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# ---------------------------------------------------------------------------------------------------\n# Limit distribuion\neigVals, eigVecs = np.linalg.eig(c2P.T)\n\n\n# Get it sorted\nidx = eigVals.argsort()[::-1]   \neigenValues = eigVals[idx]\neigenVectors = eigVecs[:,idx]\n\n# Normalize eigenvector\npi = eigenVectors[:, 0]/sum(eigenVectors[:, 0])\n\nprint ('\\neigVals=\\n', eigenValues)\n#print '\\neigVecs=\\n', eigenVectors\nprint ('\\nLimit distribution =', pi)",
      "execution_count": 14,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\neigVals=\n[1.  0.8 0.6 0.5]\n\nLimit distribution = [ 0.4  0.6 -0.  -0. ]\n"
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## ■ Number of visits of a transient state\n\n\n- Random variable $n_i$: number of visits of a state $i$ in an arbitrary long time\n\n\n- Expected number of visits of a state $j$ if initial state is $𝑖$: \n $$ E_i[n_j] < \\infty $$\n\n- We have: if state $i$ is transient: \n$$ E_i[n_j] = \\sum_{k=1}^\\infty P_{ij}^{(k)} $$\n\n- Also - fundamental matrix gives expected values:\n$$ \\left[E_i[n_j]\\right] = N $$ \n\n\n\n\n<p style=\"margin-bottom:2cm;\"></p>\n<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 14 </div>\n<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Expected number of visits of recurent states\nm = 4 # |S|\nK = 2 # number of recurent states\n\nQ = c2P[K:m, K:m]\nprint ('Part of transition matrix Q = \\n', Q)\n\nN = np.linalg.inv(np.eye(m-K)-Q)\nprint ('\\nFundamental matrix N =\\n', N)",
      "execution_count": 15,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Part of transition matrix Q = \n[[0.6 0.2]\n [0.  0.8]]\n\nFundamental matrix N =\n[[2.5 2.5]\n [0.  5. ]]\n"
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## 9.3 Transition matrix estimation\n\n\n■ Transition probability estimation\n\n■ Confidence intervals and quantiles\n\n■ Sample size determination\n\n■ Numerical aspect\n\n■ Case: telecommunication service user modeling\n\n\n<p style=\"margin-bottom:2cm;\"></p>\n<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 15 </div>\n<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
    },
    {
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## ■ Transition probability estimation\n\n- Transition probability \n$$ p_{ij} = \\frac{n_k}{n} $$\nis a statistical estimation;\n\n\n- Parameter estimation\n    - estimate and termine\n        - expected value $\\overline{x}$\n        - standard deviation $\\sigma$\n        - for a selected risk level $\\alpha$ compute $z_\\alpha$ (if normal distribution $z_{0.05}=1.96$)\n    - Confidence interval: \n$$ CI = [\\overline{x} - z_\\alpha\\frac{\\sigma}{\\sqrt{n}}, \\overline{x} + z_\\alpha\\frac{\\sigma}{\\sqrt{n}}] $$\n    - Sample size: determined from a preset confidence interval length \n    $$ |CI| = 2 z_\\alpha\\frac{\\sigma}{\\sqrt{n}} $$\n\n\n\n\n<img style=\"float: right; width: 250px; margin: 0px 20px 20px 0px;\" src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/EstimationConfInterval.png\">\n\n\n\n<p style=\"margin-bottom:7cm;\"></p>\n<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 16 </div>\n<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
    },
    {
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## ■ Confidence intervals and quantiles\n\n\n- Confidence interval visualization\n\n\n<img style=\"float: center; width: 350px; margin: 0px 20px 20px 0px;\" src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/EstimationConfIntervalVsSampleSize.png\">\n\n\n<p style=\"margin-bottom:2cm;\"></p>\n<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 17 </div>\n<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
    },
    {
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## ■ Transition matrix estimation sample size determination\n\n\n- From confidence interval size\n\n\n- Confidence interval for risk level $\\alpha=0.05$ ($z_\\alpha=1.96$)\n$$ CI = [p_0 - z_\\alpha\\sqrt{p_0(1-p_0)/n}, p_0 + z_\\alpha\\sqrt{p_0(1-p_0)/n}] $$\n\n\nFor $p=0.65$ and $|CI|=\\Delta p$ at $\\alpha=0.05$\n$$ n\\geq \\frac{4 z_\\alpha^2}{\\Delta p^2} p_0 (1-p_0) $$\nwe get\n - for $\\Delta p=0.01:$ $n\\geq 34959$,\n - for $\\Delta p=0.02:$ $n\\geq 175$,\n - for $\\Delta p=0.04:$ $n\\geq 88$.\n \n\n\n<p style=\"margin-bottom:2cm;\"></p>\n<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 18 </div>\n<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
    },
    {
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## ■ Numerical aspect of transition matrix computation\n\n\n- We need matrix power \n$$ P^n = P^{(n)} $$\n\n\n- Jordan decomposition\n$$ P = B J B^{-1},  $$\nwhere $J$ is Jordan canonical form. \n\n\n- For each class of states we have\n$$ J = \\lambda I + R $$\nand \n$$ P^n = B J^n B^{-1} $$\n\n<p style=\"margin-bottom:2cm;\"></p>\n<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 19 </div>\n<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
    },
    {
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## ■ Case: telecommunication service user modeling\n\n\n- A set of telecommunication users $U$\n\n\n- We split them into classes: $U=U_1 \\cup U_2 \\cup U_3 \\cup U_4$\n    - Very satisfied: $U_1$\n    - Satisfied: $U_2$\n    - Not satisfied: $U_3$\n    - Churners: $U_4$\n\n\n- Initial distribution: estimation of users\n\n- Results:\n    - Recurrent - transients states\n    - Stationary distribution\n\n\n\n<p style=\"margin-bottom:2cm;\"></p>\n<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 20 </div>\n<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
    },
    {
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## ■ Conclusion\n\n\n- Most useful: finite Markov chain\n- Check the transition matrix assumption: stationarity \n\n\n<p style=\"margin-bottom:2cm;\"></p>\n<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 21 </div>\n<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
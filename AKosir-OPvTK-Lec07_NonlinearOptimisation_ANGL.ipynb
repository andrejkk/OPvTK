{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img style=\"float: center; width: 100%\" src=\"https://raw.githubusercontent.com/andrejkk/TalksImgs/master/FrontSlideUpperBan.png\">\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "\n",
    "<center>\n",
    "    <H1> 7. Nonlinear optimization </H1>\n",
    "   \n",
    "\n",
    "\n",
    "<br><br>\n",
    "    <H3> Andrej Košir, Lucami, FE </H3>\n",
    "    <H4> Contact: prof. dr. Andrej Košir, andrej.kosir@fe.uni-lj.si, ZOOM https://uni-lj-si.zoom.us/j/97654707084 </H4>\n",
    "</center>\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 1 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> Goals </div>\n",
    "</div>\n",
    "\n",
    "## ■ Goal, content\n",
    "\n",
    "\n",
    "- Goal:\n",
    "    - Recognize nonlinear optimization problems\n",
    "    - Select and use solving algorithm\n",
    "  \n",
    "  \n",
    "- Geometrical interpretation\n",
    "    - Taylor formula\n",
    "    - Plane, quadratic form\n",
    "    \n",
    "- Smooth objective functions\n",
    "- Quadratic programing\n",
    "- Lagrange theorem\n",
    "- Iterative methods\n",
    "    - Gradient method\n",
    "    - Conjugate gradient method\n",
    "- A problem of initial value\n",
    "\n",
    "\n",
    "- Examples\n",
    "    - Wireless signal modelling\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 2 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> Goals </div>\n",
    "</div>\n",
    "\n",
    "## ■ How this section relates to optimization\n",
    "\n",
    "An optimization task is nonlinear if it has a nonlinear criterion function or nonlinear constraints or both. A single nonlinearity in the criterion function or in the constraints invalidates the simplex algorithm. In practice, nonlinear criterion functions are usually integrally derivable enough times (at least twice) and then gradient-based iterative methods are useful.\n",
    "\n",
    "The gradient of the criterion function indicates the direction of its maximum increase. Since in nonlinear optimization we restrict ourselves to finding the minimum without loss of generality, a good approximation to the direction leading to the minimum is the opposite direction of the gradient. The step of an iteration of the gradient method is therefore in the opposite direction of the gradient.\n",
    "\n",
    "A linear criterion function is geometrically a plane and therefore cannot have any local extrema. A non-linear function can easily have several local extrema, which is why we only introduce the definition of local and global extrema in this chapter.\n",
    "\n",
    "The main challenges in iterative methods for solving nonlinear problems are to find an initial approximation and to determine whether the extremum found is global or not. The initial approximation is usually found using other optimization methods. Determining whether the extremum found is global or not usually depends on the individual case. This is because gradient methods are local and no information is available during the iteration itself that would be useful for determining the global extreme value.\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 2 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> Sections </div>\n",
    "</div>\n",
    "\n",
    "## ■ Sections (1)\n",
    "\n",
    "\n",
    "7.1. Definition, types of extremes\n",
    "\n",
    "■ Nonlinear optimization problem $\\large{*}$\n",
    "\n",
    "■ Example: fitting parametric model\n",
    "\n",
    "■ Local and global extreme $\\large{*}$\n",
    "\n",
    "\n",
    "7.2. Quadratic optimization, constraint optimization\n",
    "\n",
    "■ Plane and quadratic form \n",
    "\n",
    "■ Quadratic form and extremes\n",
    "\n",
    "■ Taylor formula\n",
    "\n",
    "■ Quadratic optimization problem $\\large{*}$\n",
    "\n",
    "■ Constraint optimization, Lagrange theorem $\\large{*}$ \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 3 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> Sections </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## ■ Sections (2)\n",
    "\n",
    "7.3. Nonlinear optimization algorithms\n",
    "\n",
    "■ Determining extremes $\\large{*}$\n",
    "\n",
    "■ Extreme determination procedure context $\\large{*}$\n",
    "\n",
    "■ Gradient method $\\large{*}$\n",
    "\n",
    "■ Conjugated gradient method\n",
    "\n",
    "■ Nonlinear optimization solution reality\n",
    "\n",
    "\n",
    "\n",
    "7.4. Nonlinear optimization examples\n",
    "\n",
    "■ Curve fitting\n",
    "\n",
    "■ Wireless signal spreading modelling\n",
    "\n",
    "■ Recommender system\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 4 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.1 Definition, types of extremes </div>\n",
    "</div>\n",
    "\n",
    "## 7.1 Definition, types of extremes\n",
    "\n",
    "■ Nonlinear optimization problem\n",
    "\n",
    "■ Case: Wireless signal modelling \n",
    "\n",
    "■ Local and global extreme\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 5 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.1 Definition, types of extremes </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## ■ Nonlinear optimization problem\n",
    "\n",
    "- Definition (canonical form)\n",
    "$$ \\begin{matrix}\n",
    " & argmax_x c(x) \\cr\n",
    " s.t. &  \\cr\n",
    " & g_i(x) = 0, \\;i=1,\\ldots,p \\cr\n",
    " & h_j(x) \\leq 0, \\;j=1,\\ldots,m\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "- Objective function je nonlinear;\n",
    "- Constraints (feasibility predicate $\\Phi(x)$) are nonlinear;\n",
    "\n",
    "\n",
    "- Solving it: it depends on the objective function \n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 6 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.1 Definition, types of extremes </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## ■ Case: parametric model fitting\n",
    "\n",
    "- Model:\n",
    "$$ f(t;A, \\beta_1, \\beta_2) = A (1 - e^{-\\beta_1 t}) e^{-\\beta_2 t} $$\n",
    "\n",
    "\n",
    "\n",
    "- Data: \n",
    "    * $t = [0, 83, 166, 249, 332, 415]$;\n",
    "    * $y = [0, 80, 89, 86, 83, 81]$;\n",
    "    \n",
    "    \n",
    "- Criteria: squared error\n",
    "$$ c(A, \\beta_1, \\beta_2) = \\sum_{i=1}^6 |y_i - f(t_i; A, \\beta_1, \\beta_2)|^2. $$\n",
    "\n",
    "<img style=\"float: center; width: 350px; margin: 20px 20px 50px 0;\" src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/FittedModel.png\">\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 7 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.1 Definition, types of extremes </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## ■ Local in global extreme\n",
    "\n",
    "\n",
    "- Function $c: ℝ^n \\to ℝ$\n",
    "- Local minimum in  $x_0$:\n",
    "  $$ \\exists\\varepsilon > 0: \\forall x\\in K(x_0, \\varepsilon): c(x)\\geq c(x_0) $$\n",
    "- Strict local minimum in $x_0$:\n",
    "  $$ \\exists\\varepsilon > 0: \\forall x\\ne x_0\\in K(x_0, \\varepsilon): c(x)> c(x_0)  $$\n",
    "- Local maximum in $x_0$:\n",
    "  $$ \\exists\\varepsilon > 0: \\forall x\\in K(x_0, \\varepsilon): c(x)\\leq c(x_0) $$\n",
    "- Strict local maximum in $x_0$:\n",
    "  $$ \\exists\\varepsilon > 0: \\forall x\\ne x_0\\in K(x_0, \\varepsilon): c(x)< c(x_0)  $$\n",
    "- Global minimum in $x_0$:\n",
    "  $$ \\forall x\\in ℝ^n: c(x)\\geq c(x_0) $$\n",
    "- Strict global minimum in $x_0$:\n",
    "  $$ \\forall x\\ne 0\\in ℝ^n: c(x) > c(x_0) $$\n",
    "- Global maximum in $x_0$:\n",
    "  $$ \\forall x\\in ℝ^n: c(x)\\leq c(x_0) $$\n",
    "- Strict global maximum in $x_0$:\n",
    "  $$ \\forall x\\ne 0\\in ℝ^n: c(x) < c(x_0) $$\n",
    "\n",
    "\n",
    "\n",
    "<img style=\"float: right; width: 300px; margin: -150px -20px 50px 0;\" src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/LocalMinimas.png\">\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"><br><br><br><br></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 8 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.2 Quadratic optimization, constraint optimization </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## 7.2 Quadratic optimization, constraint optimization\n",
    "\n",
    "\n",
    "■ Plane and quadratic form\n",
    "\n",
    "■ Quadratic form and extremes\n",
    "\n",
    "■ Taylor formula\n",
    "\n",
    "■ Quadratic optimization problem\n",
    "\n",
    "■ Constraint optimization, Lagrange theorem\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 9 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.2 Quadratic optimization, constraint optimization </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## ■ Plane and quadratic forms\n",
    "\n",
    "- A set solving the equation \n",
    "$$ (\\vec{r} - \\vec{r}_0)^\\top.\\vec{n} = 0. $$\n",
    "is a plane having a vector $\\vec{n}$ as a normal. We set $\\vec{r}=(\\vec{x},y)$ in $\\vec{n}=(\\vec{n}_1,n_y)$ and get this result.\n",
    "\n",
    "- The direction of macimum increase of the function $c$ in $\\vec{x}$ is\n",
    "$$ \\vec{\\nabla} c(\\vec{x}) = \\vec{a}. $$\n",
    "\n",
    "- A function  \n",
    "$$ c(\\vec{x}) = a_0 + \\sum_{i=1}^n a_i (x_i-x_{i0}) = a_0 + \\vec{a}^\\top.(\\vec{x}-\\vec{x}_0) $$\n",
    "is a plane.\n",
    "\n",
    "\n",
    "- If a gradient $\\vec{\\nabla} c(\\vec{x}_0)$ exists, the function $c$ has an extreme point in $\\vec{x}_0$ if and only if the tangent plane in <br> a point $\\vec{x}_0$ is parallel to the plain of independent variable, that is if and only if \n",
    "$$ \\vec{\\nabla} c(\\vec{x}_0) = \\vec{0}. $$\n",
    "\n",
    "\n",
    "<img style=\"float: right; width: 200px; margin: -200px -20px 50px 0;\" src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/FunMinima.png\">\n",
    "\n",
    "\n",
    "- Quadratic form\n",
    "$$ c(\\vec{x}) = a_0 + \\sum_{i=1}^n a_i (x_i-x_{i0}) + \\sum_{i=1}^n\\sum_{j=1}^n a_{ij} (x_i-x_{i0})(x_j-x_{0j}) $$\n",
    "$$ = a_0 + \\vec{a}^\\top.(\\vec{x}-\\vec{x}_0) + (\\vec{x}-\\vec{x}_0)^\\top.A.(\\vec{x}-\\vec{x}_0) $$\n",
    "is either\n",
    "    - Paraboloid, bounded below\n",
    "    - Paraboloid, bounded above\n",
    "    - Saddle\n",
    "    \n",
    "If this function $c$ has an extrem, the extreem is $\\vec{x}_0$.\n",
    "    \n",
    "- in representing quadratic form by a matrix $A$ we assume $A^\\top = A$. \n",
    "\n",
    "<img style=\"float: right; width: 200px; margin: -120px -20px 50px 0;\" src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/FunMaxima.png\">\n",
    "\n",
    "<img style=\"float: right; width: 200px; margin: 0px -20px 50px 0;\" src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/FunSaddle.png\">\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"><br><br><br><br><br><br><br></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 10 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.2 Quadratic optimization, constraint optimization </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## ■ Quadratic form in extremum: case   \n",
    "\n",
    "- Quadratic form:  \n",
    "$$ c(x_1, x_2) = 2 x_1^2+3 x_1 x_2 + 5x_2^2. $$\n",
    "\n",
    "\n",
    "\n",
    "- Are there extreme points?\n",
    "\n",
    "\n",
    "<img style=\"right: center; width: 300px; margin: 0px 20px 50px 0;\" src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/ExampleMinima.png\">\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 11 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.2 Quadratic optimization, constraint optimization </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## ■ Quadratic form and extremes\n",
    "\n",
    "\n",
    "- Plane has no extremum, except on the boundary\n",
    "    - Quadratic form in a canonical form\n",
    "    - Matrix $A$ is symmetric with no loss of generality\n",
    "    - Matrix $A$ has real eigenvalues): $\\{\\lambda_1, \\ldots, \\lambda_n\\}$\n",
    "    - Schur‘s decomposition of symmetric matrix: $A=Q.D.Q^\\top$, $D=diag(\\lambda_1, \\ldots, \\lambda_n)$ is a new orthogonal base of a vector space:\n",
    "    $$ f(\\vec{x}) = \\vec{x}^\\top.A.\\vec{x} = \\vec{y}^\\top.D.\\vec{y} = \\sum_{i=1}^n \\lambda_i y_i^2. $$\n",
    "    \n",
    "\n",
    "\n",
    "- The type of the extremum is independent of a new base, only eigenvalues matters:\n",
    "    - $\\lambda_i \\geq 0 \\forall i$ ($A$ is positive definite): local minimum\n",
    "    - $\\lambda_i > 0 \\forall i$ ($A$ is strictly positive definite): strict local minimum\n",
    "    - $\\lambda_i \\leq 0 \\forall i$ ($A$ is negative definite): local maximum\n",
    "    - $\\lambda_i < 0 \\forall i$ ($A$ is positive definite): strict local maximum\n",
    "    - $\\lambda_i$ mixed signs  ($A$ not definite): no extreme\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 12 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to demonstrate Schur matrix decomposition in the interpretation of \n",
    "# extreme points - signs of eigenvalues decides between minimum, maximum and saddle\n",
    "\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "\n",
    "A = np.array([[2, 1.5], [1.5, 5]])\n",
    "\n",
    "\n",
    "#schA = linalg.schur(A)\n",
    "#D = schA[0]\n",
    "#axs = schA[1]\n",
    "\n",
    "#print \"Eigenvalues D\\n\", D\n",
    "#print \"Axes\\n\", axs\n",
    "\n",
    "\n",
    "# It is enough and more computatinally effective to find only eigenvalues\n",
    "eigA = linalg.eig(A)\n",
    "print (\"Eigenvalues eigA\\n\", eigA)\n",
    "\n",
    "\n",
    "A1 = np.array([[4, 0], [0, 6]])\n",
    "eigA1 = linalg.eig(A1)\n",
    "print (\"Eigenvalues eigA1\\n\", eigA1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.2 Quadratic optimization, constraint optimization </div>\n",
    "</div>\n",
    "\n",
    "## ■ Taylor's formula\n",
    "\n",
    "\n",
    "- Taylor formula of a function of several variables: \n",
    "$$ f(\\vec{x}_0 + \\vec{h}) = f(\\vec{x}_0) + \\vec{\\nabla} f(\\vec{x}_0).\\vec{h} \n",
    "+ \\vec{h}^\\top.Hf(\\vec{x}_0).\\vec{h} + O(|\\vec{h}|^3) $$\n",
    "where\n",
    "    - Gradinet  $\\vec{\\nabla} f(\\vec{x}) = [\\frac{\\partial f(\\vec{x})}{\\partial x_1}, \\ldots, \\frac{\\partial f(\\vec{x})}{\\partial x_n}]$ \n",
    "    - Hesse matrix: $Hf(\\vec{x}) = [\\frac{\\partial^2 f(\\vec{x})}{\\partial x_i x_j}]_{ij}$. Symmetric when $f\\in \\cal C^{(2)}$\n",
    "\n",
    "\n",
    "- Geometrical interpretation\n",
    "- For small $\\vec{h}$ it is enough to analyze quadratic form\n",
    "\n",
    "\n",
    "\n",
    "- Relation to optimization: $f\\in \\cal C^{(2)}$\n",
    "    - Extremum in the interior  $\\Rightarrow$ $\\vec{\\nabla} f(\\vec{x}_0)$ (sufficient but not necessary – a list of candidates)\n",
    "    - Is it an extremum: spectral analysis of Hessian $Hf(\\vec{x}_0)$.\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 13 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.2 Quadratic optimization, constraint optimization </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## ■ Quadratic optimization problem\n",
    "\n",
    "- Quadratic optimization: objective function of the form (centered at $\\vec{0}$)\n",
    "$$ f(\\vec{x}) = a_0 + \\vec{a}^\\top.\\vec{x} + \\frac{1}{2} \\vec{x}^\\top.A.\\vec{x}  $$\n",
    "\n",
    "\n",
    "- Symmetric matrix je positive definite:\n",
    "    - Def: for every $\\vec{x}\\ne\\vec{0}$ we have $\\vec{x}^\\top.A.\\vec{x} > 0$.\n",
    "    - Equivalent: eigenvalues so strictly positive: $\\lambda_i > 0$.\n",
    "    \n",
    "    \n",
    "- Quadratic form je strictly convex if and only if je matrix $A$ positive definite.  \n",
    "\n",
    "\n",
    "- Let a matrix $A$ is positive definite. Function  \n",
    "$$ f(\\vec{x}) = a_0 + \\vec{a}^\\top.\\vec{x} + \\frac{1}{2} \\vec{x}^\\top.A.\\vec{x} $$\n",
    "has an ekstrem $\\vec{x}^*$ if and only if $\\vec{x}^*$ is a solution of\n",
    "$$ \\vec{\\nabla} f(\\vec{x}^*) = A.\\vec{x}^* + \\vec{a} = \\vec{0}. $$\n",
    "\n",
    "\n",
    "- Relation to the Taylor‘s formula \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 14 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.2 Quadratic optimization, constraint optimization </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## ■ Optimization of quadratic norm objective function\n",
    "\n",
    "\n",
    "- Objective function  \n",
    "$$ c(\\vec{x}) = \\|\\vec{f}(\\vec{x}) - \\vec{b}\\|_2 $$ \n",
    "- Quadratic norm represents „energy“\n",
    "- Quadratic norm is given by inner (dot) product \n",
    "$$ \\|\\vec{x}\\|_2^2 = \\vec{x}^\\top.\\vec{x}  $$\n",
    "- Shortest distance is the perpendicular one\n",
    "\n",
    "\n",
    "\n",
    "- Linear / linearized case  \n",
    "$$ c(\\vec{x}) = \\|A.\\vec{x} - \\vec{b}\\|_2 $$\n",
    "of optimization has an explicit solution\n",
    "$$ \\vec{x}^* = A^\\dagger.\\vec{x} = (A^\\top.A)^{-1}.A.\\vec{b} = argmin_x \\|A.\\vec{x} - \\vec{b}\\|_2.  $$\n",
    "- Moore-Penrose generalized matrix inverse (Python: numpy.linalg.pinv)\n",
    "    - the solution of $A\\vec{x}=\\vec{b}$ is \n",
    "    - If a matrix $A$ is invertible, the solution is $\\vec{x}^* = A^{-1}.\\vec{b}$ and the minimum value is $c(\\vec{x}^*)=0$.\n",
    "\n",
    "- Note that the matrix $A$ can be obtained from any $\\cal C^{(2)}$ function $f$ by using the first terms of Taylor formula. \n",
    "  \n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 15 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized inverse: \n",
      "[[-0.24637681  0.47826087]\n",
      " [-0.01449275  0.08695652]\n",
      " [ 0.37681159 -0.26086957]]\n",
      "Optimal solution \n",
      "[ 0.71014493  0.15942029 -0.14492754]\n"
     ]
    }
   ],
   "source": [
    "# This is to demonstrate that the solution to the quadratic norm objective function \n",
    "# optimisation problem is solved by a generalised (Penrose) inverse of linearised function $f$. \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[2, 1, 4], [3, 1, 2]])\n",
    "b = np.array([1, 2])\n",
    "\n",
    "Ap = np.linalg.pinv(A)\n",
    "\n",
    "x_o = np.dot(Ap,b)\n",
    "\n",
    "print (\"Generalized inverse: \\n\", Ap)\n",
    "print (\"Optimal solution \\n\", x_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.2 Quadratic optimization, constraint optimization </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## ■ Constrained optimization, Lagrange‘s theorem\n",
    "\n",
    "-  **Theorem** Let $c, g_i:ℝ^n\\to ℝ$ in $c, g_i\\in \\cal C^{(2)}$ for all $i=1,\\ldots,m$. Then the extremum of a Lagrange‘s function\n",
    "$$ C(\\vec{x}, \\lambda_1, \\ldots, m) = c(\\vec{x}) + \\sum_{i=1}^m \\lambda_i g_i(\\vec{x}) $$\n",
    "is a constrained extremum of a function $c$ with constraints\n",
    "$$ g_i(\\vec{x})=0, \\quad i=1,\\ldots,m. $$\n",
    "\n",
    "\n",
    "- Generalization is Karush–Kuhn–Tuckerjev theorem covering inequalities in the constraints:\n",
    "$$  g_i(x) = 0, \\;i=1,\\ldots,p $$\n",
    "$$  h_j(x) \\leq 0, \\;j=1,\\ldots,m $$\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 16 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to do calculations of the case 7.5 demonstrating the application of Lagrange's theorem transforming \n",
    "# constraint optimisation into a non-constraint one \n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize, rosen, rosen_der\n",
    "\n",
    "# Cost function\n",
    "def c(X):\n",
    "    return 4*(X[0]-2)**2 + 3*(X[1]-1)**2 + 2\n",
    "\n",
    "# Constrain\n",
    "def g(X):\n",
    "    return (X[0]-3)**2 + 3*(X[1]-2)**2 - 1\n",
    "\n",
    "\n",
    "# Gradient\n",
    "def grad(X):\n",
    "    px1 = 4*(X[0]-2)\n",
    "    px2 = 6*(X[1]-1)\n",
    "    return [px1, px2]\n",
    "\n",
    "# Hessian\n",
    "def Hc(X):\n",
    "    H = [[4, 0], [0, 6]]\n",
    "    return H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate solution: [1.99999979 1.00000017]\n",
      "Grad:  [-8.586755839701254e-07, 9.967837035773641e-07]\n",
      "Eigs of H(X1) [4. 6.]\n"
     ]
    }
   ],
   "source": [
    "# Unconditional optimisation\n",
    "x0 = np.array([1,1])\n",
    "res = minimize(c, x0, method='Nelder-Mead', tol=1e-6)\n",
    "\n",
    "xS = res.x\n",
    "print ('Candidate solution:', xS)\n",
    "\n",
    "# Test grdient\n",
    "print ('Grad: ', grad(xS))\n",
    "\n",
    "\n",
    "# Identify types of extreme points\n",
    "las, eigvs = np.linalg.eig(Hc(xS))\n",
    "print (\"Eigs of H(X1)\", las)\n",
    "\n",
    "\n",
    "\n",
    "# Conclussion\n",
    "# True solution is [2,1] as seen from function\n",
    "# grad(xS) is close to zero => the solution xS is OK\n",
    "# Eigenvalues of Hc(xS) are all positive => xS is a Minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate solution: [2.27478447 1.60248162]\n",
      "Grad:  [1.099137890607322, 3.6148897022026314]\n",
      "Eigs of H(X1) [4. 6.]\n"
     ]
    }
   ],
   "source": [
    "# Conditional solution\n",
    "\n",
    "# Condition\n",
    "cons = {'type':'eq', 'fun': g}\n",
    "x0 = np.array([1,1])\n",
    "res = minimize(c, x0, constraints=cons, tol=1e-6)\n",
    "\n",
    "xS = res.x\n",
    "print ('Candidate solution:', xS)\n",
    "\n",
    "# Test grdient\n",
    "print ('Grad: ', grad(xS))\n",
    "\n",
    "\n",
    "# Identify types of extreme points\n",
    "las, eigvs = np.linalg.eig(Hc(xS))\n",
    "print (\"Eigs of H(X1)\", las)\n",
    "\n",
    "# Conclusion: Gradient is not close to zero what is OK for conditional solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: -3256512.410913789\n",
      " hess_inv: array([[ 0.13826167, -0.03335401, -0.09240454],\n",
      "       [-0.03335401,  0.01838926, -0.02874768],\n",
      "       [-0.09240454, -0.02874768,  0.24825159]])\n",
      "      jac: array([21185.1875 , 53034.96875, 13003.9375 ])\n",
      "  message: 'Desired error not necessarily achieved due to precision loss.'\n",
      "     nfev: 480\n",
      "      nit: 5\n",
      "     njev: 117\n",
      "   status: 2\n",
      "  success: False\n",
      "        x: array([ -39.15540555, -103.96153179, -253.22761072])\n",
      "Conditional solution: [ -39.15540555 -103.96153179 -253.22761072]\n",
      "Eigs of H(X1) [  88.31262361 -502.17730819 -589.04575829]\n"
     ]
    }
   ],
   "source": [
    "# Conditional solution using Lagrange multiplicators\n",
    "\n",
    "# Lagrange function\n",
    "def C(X):\n",
    "    return 2*(X[0]-2)**2 + 3*(X[1]-1)**2 + 2 + X[2]*((X[0]-3)**2 + (X[1]-2)**2 - 1)\n",
    "    #return c(X[0:2]) + X[2]*g(X[0:2])\n",
    "\n",
    "# Gradient\n",
    "def grad(X):\n",
    "    return [4*(X[0]-2) + 2*X[2]*(X[0]-3), 6*(X[1]-1) + 2*X[2]*(X[1]-2), (X[0]-3)**2 + (X[1]-2)**2 - 1]\n",
    "    \n",
    "# Hessian\n",
    "def Hc(X):\n",
    "    H = [[4 + 2*X[2], 0, 2*(X[0]-3)], [0, 6+2*X[2], 2*(X[1]-2)], [2*(X[0]-3), 2*(X[1]-2), 0]]\n",
    "    return H\n",
    "\n",
    "\n",
    "\n",
    "X0 = np.array([3,0,1])\n",
    "res = minimize(C, X0, tol=1e-6)\n",
    "print (res)\n",
    "\n",
    "XS = res.x\n",
    "print ('Conditional solution:', XS)\n",
    "\n",
    "las, eigvs = np.linalg.eig(Hc(XS))\n",
    "print (\"Eigs of H(X1)\", las)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.3. Nonlinear optimization algorithms </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## 7.3. Nonlinear optimization algorithms\n",
    "\n",
    "■ Determining extremes\n",
    "\n",
    "■ Extreme determination procedure context\n",
    "\n",
    "■ Gradient method\n",
    "\n",
    "■ Conjugated gradient method\n",
    "\n",
    "■ Nonlinear optimization solution reality\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 17 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.3. Nonlinear optimization algorithms </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## ■ Basic reasoning of iterative methods (1)\n",
    "\n",
    "\n",
    "- Gradient detects only feasible region interior candidates\n",
    "\n",
    "\n",
    "- Procedure\n",
    "    1. Feasible region interior: <br>\n",
    "        1. Candidates for extremum:  $\\vec{\\nabla} c(\\vec{x})=0: \\vec{x}_1^*, \\vec{x}_2^*, \\ldots$ <br>\n",
    "        2. Type of extremum: analysis of $H c(\\vec{x}_1^*), H c(\\vec{x}_2^*), \\ldots $\n",
    "    \n",
    "    2. Feasible region boundary:\n",
    "        1. Parametrization of feasible region boundary;\n",
    "        2. Same procedure as for interior points;\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 18 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.3. Nonlinear optimization algorithms </div>\n",
    "</div>\n",
    "\n",
    "## ■ Basic reasoning of iterative methods (2)\n",
    "\n",
    "\n",
    "- When iterations: equation $\\vec{\\nabla} c(\\vec{x})=0$ is not solvable (usually it is not)\n",
    "- What is iteration solution\n",
    "    - Approximation at the step $k$ is  $\\vec{x}_k$;\n",
    "    - Initial approximation  $\\vec{x}_0$;\n",
    "    - Iteration step: $\\vec{x}_{k+1} = F(\\vec{x}_k, c)$;\n",
    "    - Termination condition: $d(\\vec{x}_k, \\vec{x}_{k-1}) < \\epsilon$\n",
    "\n",
    "\n",
    "\n",
    "- Time complexity of one single step\n",
    "- Convergence type: \n",
    "    - linear (1 decimal digits per step), \n",
    "    - quadratic (2 decimal digits per step) \n",
    "\n",
    "\n",
    "- Initial approximation issue:\n",
    "    - Robust algorithm like genetic algorithm run prior to iteration\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 19 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.3. Nonlinear optimization algorithms </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## ■ Gradient method\n",
    "\n",
    "\n",
    "- Formulation: unconstrained minimization of smooth $c(\\vec{x})$\n",
    "- Procedure - algorithm:\n",
    "    - Initial approximation $\\vec{x}_0$: other methods or manual estimation\n",
    "    - Direction of search $\\vec{r}_k=-\\vec{\\nabla}c(\\vec{x}_k)$ \n",
    "    - Step: $\\vec{x}_{k+1} = \\vec{x}_k  - \\alpha_k \\vec{\\nabla}c(\\vec{x}_k)$\n",
    "    - Step size – several options:\n",
    "        - Linearization: \n",
    "        $$ \\alpha_k = \\frac{\\vec{x}_k^\\top.Hc(\\vec{x}_k).\\vec{x}_k}{\\vec{x}_k^\\top.\\vec{x}_k} $$ \n",
    "        - Minimization in one dimension\n",
    "        $$ \\alpha \\mapsto c(\\vec{x}_k + \\alpha \\vec{r}_k) $$\n",
    "        - Finding zeros of the equation\n",
    "        $$ \\vec{x}_k^\\top.\\vec{\\nabla}(\\vec{x}_k + \\alpha \\vec{r}_k) = 0  $$\n",
    "\n",
    "\n",
    "\n",
    "- Convergence: linear (one decimal digit per step)\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 20 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.3. Nonlinear optimization algorithms </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## ■ Conjugate gradient method (1)\n",
    "\n",
    "- Formulation: unconstrained minimization of smooth  $c(\\vec{x})$\n",
    "- Procedure - algorithm:\n",
    "    - Initial approximation  $c(\\vec{x})_k$: other methods or manual estimation\n",
    "    - Direction of search: $\\vec{d}_k = \\vec{r}_k + \\beta \\vec{d}_{k-1}$, \n",
    "    - Step: $\\vec{r}_k = -\\vec{\\nabla} c(\\vec{x}_k)$;\n",
    "    - Selection of $\\beta$\n",
    "        - Polak-Ribiere: \n",
    "        $$ \\beta_k = \\frac{\\vec{r}_k^\\top.\\vec{r}_k}{(\\vec{r}_k - \\vec{r}_{k-1})^\\top.\\vec{r}_{k-1}} $$\n",
    "        - Fletcher-Reeves: \n",
    "        $$ \\beta_k = \\frac{\\vec{r}_k^\\top.\\vec{r}_k}{\\vec{r}_{k-1}^\\top.\\vec{r}_{k-1}} $$\n",
    "    - Algorithm step: \n",
    "    $$ \\vec{x}_{k+1} = \\vec{x}_k - \\alpha_k \\vec{d}_k $$\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 21 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.3. Nonlinear optimization algorithms </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## ■ Conjugate gradient method (2)\n",
    "\n",
    "\n",
    "- Procedure (cont.):\n",
    "    - Step size – several options :\n",
    "        - Linearization:\n",
    "        $$ \\alpha_k = \\frac{\\vec{d}_k^\\top.Hc(\\vec{x}_k).\\vec{d}_k}{\\vec{r}_k^\\top.\\vec{d}_k} $$\n",
    "        - Minimization in one dimension: minimise\n",
    "        $$ \\alpha \\mapsto c(\\vec{x}_k + \\alpha \\vec{r}_k) $$\n",
    "        - Finding zeros of the equation\n",
    "        $$ \\vec{d}_k^\\top.\\vec{\\nabla}(\\vec{x}_k + \\alpha \\vec{d}_k) = 0 $$\n",
    "    - Termination condition: repeat until \n",
    "        $$ d(\\vec{x}_{k+1} - \\vec{x}_k) < \\varepsilon $$\n",
    "    \n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 22 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.3. Nonlinear optimization algorithms </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## ■ Reality check: typical procedure\n",
    "\n",
    "\n",
    "- Finding best form of objective function\n",
    "- Finding best algorithm – „cook and look method“\n",
    "\n",
    "\n",
    "\n",
    "- Combination of two methods:\n",
    "    1. Initial approximation: for instance  genetic algorithm\n",
    "    2. Accurate solution: for instance gradient method\n",
    "\n",
    "\n",
    "\n",
    "- Typical procedure\n",
    "    1. Analytical solution of $\\vec{\\nabla}c(\\vec{x})=\\vec{0}$\n",
    "    2. Combination of several methods\n",
    "    3. Large number of trials\n",
    "        1. Parameter settings\n",
    "        2. Objective function reformulations \n",
    "        3. Initial approximations \n",
    "    4. New algorithm? Typically no, modification of existing ones \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 23 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.3. Nonlinear optimization algorithms </div>\n",
    "</div>\n",
    "\n",
    "## ■ Reality check: optimisation tools are complex\n",
    "\n",
    "\n",
    "- IBM CPLEX\n",
    "    - Best available\n",
    "    - Algorithm selector\n",
    "\n",
    "- Custom solutions\n",
    "\n",
    "<img style=\"float: right; width: 350px; margin: 0px 20px 20px 0px;\" src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/CPLEX_UI.png\">\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 1 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.4. Applications </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## 7.4. Applications\n",
    "\n",
    "■ Curve fitting\n",
    "\n",
    "■ Wireless signal spreading modelling\n",
    "\n",
    "■ Recommender system\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 24 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.4. Applications </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## ■ Intro case: Curve fitting\n",
    "\n",
    "\n",
    "- Objective function, model\n",
    "$$ f(t;A, \\beta_1, \\beta_2) = A (1 - e^{-\\beta_1 t}) e^{-\\beta_2 t} $$\n",
    "$$ c(A, \\beta_1, \\beta_2) = \\sum_{i=1}^6 |y_i - f(t_i; A, \\beta_1, \\beta_2)|^2. $$\n",
    "\n",
    "\n",
    "- Solution: gradient method, \n",
    "    - $A_0=150$\n",
    "    - $\\beta_{10}=0.01$;\n",
    "    - $\\beta_{20}=0.001$;\n",
    "\n",
    "\n",
    "- Solution: estimation and confidence interval\n",
    "    - $A=97.2$ $(91.59, 102.8)$;\n",
    "    - $\\beta_1=0.02339$ $(0.019, 0.027)$;\n",
    "    - $\\beta_2=0.0004545$ $(0.00028, 0.00063)$;\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 25 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 1.408172\n",
      "         Iterations: 22\n",
      "         Function evaluations: 336\n",
      "         Gradient evaluations: 81\n",
      "Results:  [9.71935622e+01 2.33899353e-02 4.54424755e-04]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Curve fitting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "t = [0, 83, 166, 249, 332, 415];\n",
    "y = [0, 80, 89, 86, 83, 81];\n",
    "\n",
    "# Cost function\n",
    "def f(t, x):\n",
    "    return x[0]*(1 - np.e**(-x[1]*t))*np.e**(-x[2]*t)\n",
    "                 \n",
    "def c(x):\n",
    "    err = 0\n",
    "    for ii in range(6):\n",
    "        err += (y[ii] - f(t[ii], x))**2 \n",
    "    return err\n",
    "\n",
    "\n",
    "# Initial value\n",
    "A0 = 200\n",
    "b10 = 0.01\n",
    "b20 = 0.001\n",
    "x0 = np.array([A0, b10, b20])\n",
    "\n",
    "# Optimisation\n",
    "res = minimize(c, x0, options={'disp': True})\n",
    "print ('Results: ', res.x)\n",
    "\n",
    "\n",
    "# Plot results\n",
    "t_s = np.arange(0.0, 415, 1.0)\n",
    "y_s = f(t_s, res.x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, y, 'bo')\n",
    "ax.plot(t_s, y_s, color = 'm')\n",
    "\n",
    "ax.set(xlabel='time [s]', ylabel='Conc.',\n",
    "       title='Concentration')\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.4. Applications </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## ■ Wireless signal spreading modelling (1)\n",
    "\n",
    "\n",
    "- Model: A. F. Molisch: Wireless Communications, 2nd Edition, Wiley, 2010\n",
    "- Članek: M. Pesko, T. Javornik, V. Luka, A. Košir, M. Štular, M. Mohorčič, _The indirect self-tuning method for constructing radio environment map using omnidirectional or directional transmitter antenna. EURASIP Journal on wireless communications and networking_, 2015.\n",
    "\n",
    "\n",
    "- Problem: \n",
    "    - Predict wireless signal strength\n",
    "    - Network quality estimation\n",
    "    - Network planning \n",
    "\n",
    "\n",
    "\n",
    "- Solution: Signal spreading model fitting\n",
    "    - Parametrized spreading model: \n",
    "    $$ \\text{PathLoss}_{dB} (A_0, A_1, A_2, A_3) $$\n",
    "    - Objective function: model fitting error:\n",
    "    $$ c((A_0, A_1, A_2, A_3)) = \n",
    "    \\sum_{k=1}^m |\\text{PathLoss}_{dB} (A_0, A_1, A_2, A_3) - \\text{RealLoss}_k|^2  $$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Optimization task\n",
    "  $$ (A_0, A_1, A_2, A_3)^* = argmin_{A_0, A_1, A_2, A_3} c(A_0, A_1, A_2, A_3). $$\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 26 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.4. Applications </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "## ■ Wireless signal spreading modelling (2)\n",
    "\n",
    "\n",
    "- Signal spreading model **Empirical Okumura–Hata (OH)**: estimation of wireless signal loss: \n",
    "    $$ \n",
    "    \\text{PathLoss}_{dB} (A_0, A_1, A_2, A_3) \n",
    "      = HOA(A_0, A_1, A_2, A_3) + mk(q) + \\sqrt{(\\alpha\\text{KDRF})^2 + \\text{JDRF}^2}  $$\n",
    "      \n",
    "    $$ HOA(A_0, A_1, A_2, A_3) = A_0 + A_1\\log(\\frac{d(q)}{10^3})\n",
    "     + A_2\\log(H_{effi}) + A_3\\log(\\frac{d(q)}{10^3})\\log(H_{effi})\n",
    "     - 3.2\\log^2(11.75 hm) + 44.49 \\log(F) - 4.78\\log^2(F).  $$\n",
    "    \n",
    "    \n",
    "    \n",
    "- Oznake:\n",
    "    - $A_0, A_1, A_2, A_3$ model parameters to be estimated;\n",
    "    - $H_{effi}$ [m] effective antena height;\n",
    "    - $mk(q)$  signal attenuation from overlapping in dB;\n",
    "    - $\\text{KDRF}$ signal loss from obstacles;\n",
    "    - $\\alpha$ control parameters for diffraction\n",
    "    - $JDFR$ earth curvature related loss in dB\n",
    "    - $d(q)$ distances from transmitter to measurements points\n",
    "    - $hm$ antena height\n",
    "    - $F$ transmitter frequency in MHz\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 27 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.4. Applications </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## ■ Wireless signal spreading modelling (3)\n",
    "\n",
    "\n",
    "- Solution\n",
    "    - Genetic algorithm: OK\n",
    "    - Solving  $\\vec{\\nabla} c(\\vec{A}) = \\vec{0}$ led to a system of linear equations\n",
    "    $$ G.\\vec{A} = \\vec{b} $$\n",
    "    - Solution \n",
    "    $$(A_0, A_1, A_2, A_3)^* =(37.42,  34.85,  −11.96, −0.091). $$\n",
    "\n",
    "\n",
    "\n",
    "- Further work \n",
    "    - Solution sensitivity analysis\n",
    "    - Error analysis: required number of measurements\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 28 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.4. Applications </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## ■ Recommender systems (1) \n",
    "\n",
    "#### Application problem: information overflow for human users\n",
    "  - too many search engine results: books, movies, tourist destinations, ...\n",
    " \n",
    "#### Solution: Recommender system\n",
    "  - customized search results\n",
    "  - three approaches:\n",
    "      - content based: _The person who was interested in the past is still interested in it._ How to measure the similarity of content?\n",
    "      - collaborative: _The user interested in similar users is also interested in this user._ How to measure the similarity between the users?\n",
    "      - hybrid: (a combination of both approaches)\n",
    "     \n",
    "     \n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 29 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.4. Applications </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## ■ Recommender systems (2) \n",
    "\n",
    "\n",
    "#### Algorithmic Solution: Matrix Factorization\n",
    "\n",
    "- Paper: Y. Koren, R. Bell, C. Volinsky: MATRIX FACTORIZATION TECHNIQUES FOR RECOMMENDER SYSTEMS, IEEE Computer Society, 2009.\n",
    "- users $ u \\in U $, the content $ h \\in H $\n",
    "- data matrix of user ratings - mostly has **unknown values** (n.d. = no data)\n",
    "$$ D = [r_ {uh}] _ {u \\ in U, h \\ in H} $$\n",
    "\n",
    "\n",
    "\n",
    "- we use notations $P_ {(u)}$ for $u$-th row of the matrix $P$ and $Q_{(h)}$ for the $h$-th row of the matrix $Q$.\n",
    "\n",
    "\n",
    "\n",
    "- What is the matrix factorization: $ Q.R $, ...\n",
    "\n",
    "\n",
    "\n",
    "- the concept of latent features (properties)\n",
    "     - features\n",
    "     - latent features\n",
    "\n",
    "\n",
    "\n",
    "- Matrix factorization\n",
    "     - we choose the number of $M$ features that can be arbitrary, typically \n",
    "     $M \\in \\{3, \\ ldots, 10 \\} $.\n",
    "      - Factoring is to express the data matrix $D$ into a product of two matrices of the form\n",
    "$$ P.Q^\\top = D $$\n",
    "     - most values are missing\n",
    "$$ \n",
    "\\begin{bmatrix}\n",
    " p_{11} & \\ldots & p_{1M} \\cr\n",
    " \\vdots & \\ddots & \\vdots \\cr\n",
    " \\vdots & \\ddots & \\vdots \\cr\n",
    " \\vdots & \\ddots & \\vdots \\cr\n",
    " p_{n1} & \\ldots & p_{nM}\n",
    "\\end{bmatrix}\n",
    ".\\begin{bmatrix}\n",
    " q_{11} & \\ldots & \\ldots & \\ldots & q_{M1} \\cr\n",
    " \\vdots & \\ddots & \\ldots & \\ldots & \\vdots \\cr\n",
    " q_{M1} & \\ldots & p_{Mm}\n",
    "\\end{bmatrix}\n",
    " = \n",
    "\\begin{bmatrix}\n",
    " n.d. & \\ldots & \\ldots & \\ldots & n.d. \\cr\n",
    " \\vdots & \\vdots & \\vdots & \\vdots & \\vdots  \\cr\n",
    " \\vdots & \\vdots & r_{uh} & \\vdots & \\vdots  \\cr\n",
    " \\vdots & \\vdots & \\vdots & \\vdots & \\vdots  \\cr\n",
    " n.d. & \\ldots & \\ldots & \\ldots & n.d.\n",
    "\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 30 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.4. Applications </div>\n",
    "</div>\n",
    "\n",
    "## ■ Recommender systems (3) \n",
    "\n",
    "\n",
    "#### Basic reasoning\n",
    "\n",
    "\n",
    "- The matrices $P$ and $Q$ are defined in such a way that the equality applies to all **known values of the estimates** of the matrix $D$. This detemines all values of matrices $P$ and $Q$.\n",
    "\n",
    "\n",
    "- Assumption: if matrices $P$ and $Q$ correctly present known users' estimates, **would also correctly evaluate unknown estimates.**. By assuming this, we find **how the user will evaluate the content he/she has not yet seen.**\n",
    "- Since the $P$ rows belong to individual users and \"work\" for all content $ h\\in H$, $P_{(u)}$ is the vector of the latent feature of the user $u$\n",
    "- Because the $Q$ rows belong to individual content and are \"working\" for all content $u \\in U$, $Q_{(h)} $ is a vector of latent features of the content $h$\n",
    "\n",
    "\n",
    "\n",
    "#### How It Works\n",
    "1. Using the estimated matrices $P$ and $Q$ determine the missing values of the $D$ matrix, that is, the missing user ratings\n",
    "$$ P.Q^\\top = \\hat{D} $$\n",
    "2. We use these estimates by arranging them in descending order and presented to the user, for example, the first best $15$ items;\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 31 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.4. Applications </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## ■ Recommender systems (4) \n",
    "\n",
    "#### Optimisation problem\n",
    "Regularised cost function \n",
    "$$ c(D, P, Q) = \\sum_{u,h\\in D'} (r_{uh} - P_{(u)}.Q_{(h)})^2 + \\lambda (\\|P_{(u)}\\|^2 + \\|Q_{(h)}\\|^2) $$\n",
    "Second term $\\lambda (\\|P_{(u)}\\|^2 + \\|Q_{(h)}\\|^2)$ is a regularisation term, it prefers smaller enries of matrices $P$ and $Q$. It somehow represents constraints.\n",
    "\n",
    "\n",
    "\n",
    "Because of the regularisation term, the optimisation problem is unconstrained:\n",
    "$$ argmin_{P,Q} c(D, P, Q) $$\n",
    "\n",
    "\n",
    "#### Gradient of regularised cost function\n",
    "\n",
    "An estimation error at $r_{uh}$ is $e_{uh} = r_{uh} - P_{(u)}.Q_{(h)}$. \n",
    "Direct calculation of partial derivatives by the $i$-the entry $P_{(u)i}$ and $P_{(h)i}$ of matrix rows $P_{(u)}$ and $Q_{(h)}$ are\n",
    "$$ \\frac{\\partial}{\\partial P_{(u)i}} c(D, P, Q) = -2\\left(r_{uh} - P_{(u)}.Q_{(h)}\\right) Q_{(h)i} + 2 \\lambda P_{(u)i} \n",
    "  = -2 e_{uh} Q_{(h)i} + 2 \\lambda P_{(u)i}. $$\n",
    "$$ \\frac{\\partial}{\\partial Q_{(h)i}} c(D, P, Q) = -2\\left(r_{uh} - P_{(u)}.Q_{(h)}\\right) P_{(u)i} + 2 \\lambda Q_{(h)i} \n",
    "  = -2 e_{uh} P_{(u)i} + 2 \\lambda Q_{(h)i}. $$\n",
    "\n",
    "\n",
    "\n",
    "We combine a coorection of $i$-th entry $P_{(u)i}$ and $P_{(h)i}$ into a vector form, that is for matrix $P$ and $Q$ rows according to the gradient algorithm\n",
    "$$ \\vec{x}_{k+1}=\\vec{x}_k - \\alpha_k \\vec{\\nabla} c(\\vec{x}_k), $$\n",
    "and obtain \n",
    "$$ P_{(u)k+1} = P_{(u)k} + \\alpha_k \\left(e_{uh} Q_{(h)k} - \\lambda P_{(u)k}\\right)  $$\n",
    "$$ Q_{(u)k+1} = Q_{(u)k} + \\alpha_k \\left(e_{uh} P_{(u)k} - \\lambda Q_{(u)k}\\right)  $$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The stochastic gradient descent algorithm thus intebrates according to the known values of the data matrix of estimates $[r_{uh}]$ and corrects approximation of the matrix rows $P_{(u)}$ and $Q_{(u)}$ according to the above equations.\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 32 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.4. Applications </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## ■ Recommender system (5)\n",
    "\n",
    "\n",
    "#### Algoritmic solution: Stohastic gradient decent\n",
    "\n",
    "- misleading name: no stochastic steps\n",
    "- we already determined objective function and its gradient\n",
    "\n",
    "- Pseudocode\n",
    "\n",
    ">**Algorithm 1:** Stochastic gradient decent  \n",
    ">\n",
    ">**Require:** Data matrix of ratings $D=[r_{uh}]$  \n",
    ">**Ensure:** Latent feature matrices $P$ in $Q$  \n",
    ">\n",
    ">1: Initialize initial values <br> \n",
    ">2: **while** (convergence) <br>\n",
    ">3: &emsp;Get available values from $D$ [available ones] <br>\n",
    ">4: &emsp;**for** (all $r_{uh} \\in \\mathcal{D}$)  <br>\n",
    ">5: &emsp;&emsp; $(P,Q)_{new}=(P,Q) - \\alpha_k\\nabla c(D, P, Q)$ <br>\n",
    ">6: &emsp;&emsp; $(P,Q)_{new}=(P,Q)$ <br>\n",
    "\n",
    "\n",
    "\n",
    "- Further improvements: \n",
    "    - determining $\\alpha_k$\n",
    "    - contextualisation\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 33 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display:flex;font-weight:bold;font-size:0.9em;\">\n",
    "<div style=\"flex:1;width:50%;\"> 7. Nonlinear optimization  </div>\n",
    "<div style=\"flex:1;width:50%;text-align:right;\"> 7.4. Applications </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "## ■ Conclusion\n",
    "\n",
    "\n",
    "- It is important to know\n",
    "    - Problem domain specifics\n",
    "    - Basic properties of algorithms\n",
    "    - Basic properties of tools\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<div style=\"width:100%;text-align:right;font-weight:bold;font-size:1.2em;\"> 34 </div>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
